{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_loader import load_datasets\n",
    "\n",
    "(texts_train, labels_train), (texts_val, labels_val), (texts_test, labels_test) = load_datasets(folder_path='dataset', \n",
    "                                                                                                divide_by_sentence=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "texts = texts_train + texts_val + texts_test\n",
    "\n",
    "sequence_length = 50\n",
    "\n",
    "vectorizer = TextVectorization(output_sequence_length=sequence_length, standardize=None)  # standaridze=None\n",
    "\n",
    "vectorizer.adapt(data=texts)\n",
    "\n",
    "x = vectorizer(texts)\n",
    "\n",
    "# Mapping from integers to word types\n",
    "vocabulary = np.array(vectorizer.get_vocabulary())\n",
    "\n",
    "x_train = x[:len(texts_train)]\n",
    "x_val = x[len(texts_train):len(texts_train)+len(texts_val)]\n",
    "x_test = x[len(texts_train)+len(texts_val):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "labels = labels_train + labels_val + labels_test\n",
    "\n",
    "sequence_length = 50\n",
    "\n",
    "vectorizer_labels = TextVectorization(output_sequence_length=sequence_length, standardize=None)  # standaridze=None\n",
    "\n",
    "vectorizer_labels.adapt(data=labels)\n",
    "\n",
    "y = vectorizer_labels(labels)\n",
    "\n",
    "# Mapping from integers to POS tags\n",
    "vocabulary_labels = np.array(vectorizer_labels.get_vocabulary())\n",
    "\n",
    "y_train = y[:len(labels_train)]\n",
    "y_val = y[len(labels_train):len(labels_train)+len(labels_val)]\n",
    "y_test = y[len(labels_train)+len(labels_val):]\n",
    "\n",
    "n_classes = len(vocabulary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.glove_loader import load_glove\n",
    "\n",
    "embedding_dimension = 50\n",
    "\n",
    "GLOVE_embeddings = load_glove(folder_path='glove_pretrained', embedding_dim=embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_matrix_builder import build_embedding_matrix\n",
    "\n",
    "embedding_matrix = build_embedding_matrix(vocabulary=vocabulary, GLOVE_embeddings=GLOVE_embeddings, embedding_dimension=embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline_model import build_baseline_model\n",
    "\n",
    "baseline_model = build_baseline_model(sequence_length=sequence_length, n_classes=n_classes, embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 50, 50)            547450    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               [(None, 50, 128),         91648     \n",
      "                              (None, 128),                       \n",
      "                              (None, 128)]                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50, 47)            6063      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 645,161\n",
      "Trainable params: 645,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "baseline_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 11s 95ms/step - loss: 2.6905 - accuracy: 0.2862 - val_loss: 2.1904 - val_accuracy: 0.4313\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.7760 - accuracy: 0.5347 - val_loss: 1.5030 - val_accuracy: 0.6178\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.2410 - accuracy: 0.6881 - val_loss: 1.1743 - val_accuracy: 0.7011\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.9665 - accuracy: 0.7597 - val_loss: 1.0111 - val_accuracy: 0.7440\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.8084 - accuracy: 0.8014 - val_loss: 0.9072 - val_accuracy: 0.7682\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.6947 - accuracy: 0.8293 - val_loss: 0.8378 - val_accuracy: 0.7818\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.6081 - accuracy: 0.8478 - val_loss: 0.7827 - val_accuracy: 0.7952\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.5416 - accuracy: 0.8644 - val_loss: 0.7459 - val_accuracy: 0.8060\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.4880 - accuracy: 0.8765 - val_loss: 0.7314 - val_accuracy: 0.8124\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4366 - accuracy: 0.8888 - val_loss: 0.6936 - val_accuracy: 0.8169\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.3861 - accuracy: 0.9000 - val_loss: 0.6794 - val_accuracy: 0.8165\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.3495 - accuracy: 0.9081 - val_loss: 0.6676 - val_accuracy: 0.8231\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.3156 - accuracy: 0.9156 - val_loss: 0.6899 - val_accuracy: 0.8259\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.2834 - accuracy: 0.9236 - val_loss: 0.6591 - val_accuracy: 0.8200\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.2584 - accuracy: 0.9302 - val_loss: 0.6545 - val_accuracy: 0.8228\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.2311 - accuracy: 0.9379 - val_loss: 0.6850 - val_accuracy: 0.8243\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.2149 - accuracy: 0.9429 - val_loss: 0.6771 - val_accuracy: 0.8239\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1917 - accuracy: 0.9484 - val_loss: 0.6686 - val_accuracy: 0.8297\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1725 - accuracy: 0.9537 - val_loss: 0.7150 - val_accuracy: 0.8330\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.1642 - accuracy: 0.9559 - val_loss: 0.6739 - val_accuracy: 0.8306\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1450 - accuracy: 0.9616 - val_loss: 0.6879 - val_accuracy: 0.8305\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1339 - accuracy: 0.9653 - val_loss: 0.6976 - val_accuracy: 0.8325\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.1228 - accuracy: 0.9686 - val_loss: 0.7085 - val_accuracy: 0.8291\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1123 - accuracy: 0.9716 - val_loss: 0.7122 - val_accuracy: 0.8285\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.1021 - accuracy: 0.9744 - val_loss: 0.7245 - val_accuracy: 0.8273\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0941 - accuracy: 0.9759 - val_loss: 0.7436 - val_accuracy: 0.8280\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0867 - accuracy: 0.9790 - val_loss: 0.7542 - val_accuracy: 0.8287\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0789 - accuracy: 0.9815 - val_loss: 0.7567 - val_accuracy: 0.8255\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.0727 - accuracy: 0.9835 - val_loss: 0.7734 - val_accuracy: 0.8289\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0669 - accuracy: 0.9852 - val_loss: 0.7776 - val_accuracy: 0.8233\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.7896 - val_accuracy: 0.8258\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0569 - accuracy: 0.9881 - val_loss: 0.8078 - val_accuracy: 0.8268\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0526 - accuracy: 0.9895 - val_loss: 0.8069 - val_accuracy: 0.8260\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0488 - accuracy: 0.9905 - val_loss: 0.8148 - val_accuracy: 0.8274\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0432 - accuracy: 0.9918 - val_loss: 0.8282 - val_accuracy: 0.8240\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0389 - accuracy: 0.9931 - val_loss: 0.8417 - val_accuracy: 0.8257\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0358 - accuracy: 0.9946 - val_loss: 0.8508 - val_accuracy: 0.8243\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0323 - accuracy: 0.9954 - val_loss: 0.8629 - val_accuracy: 0.8222\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0297 - accuracy: 0.9960 - val_loss: 0.8776 - val_accuracy: 0.8238\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0274 - accuracy: 0.9967 - val_loss: 0.8853 - val_accuracy: 0.8240\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.0253 - accuracy: 0.9966 - val_loss: 0.8989 - val_accuracy: 0.8225\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0233 - accuracy: 0.9971 - val_loss: 0.9090 - val_accuracy: 0.8209\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0216 - accuracy: 0.9975 - val_loss: 0.9123 - val_accuracy: 0.8224\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.0198 - accuracy: 0.9977 - val_loss: 0.9282 - val_accuracy: 0.8243\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0183 - accuracy: 0.9978 - val_loss: 0.9418 - val_accuracy: 0.8224\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 0.9508 - val_accuracy: 0.8219\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: 0.9558 - val_accuracy: 0.8222\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0149 - accuracy: 0.9982 - val_loss: 0.9672 - val_accuracy: 0.8195\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 0.9719 - val_accuracy: 0.8203\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.9835 - val_accuracy: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25dedce55d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without using punctuation\n",
    "baseline_model.fit(x=x_train, y=y_train, batch_size=32, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 12s 94ms/step - loss: 2.8421 - accuracy: 0.2592 - val_loss: 2.2784 - val_accuracy: 0.4334\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 1.7607 - accuracy: 0.5730 - val_loss: 1.3702 - val_accuracy: 0.6663\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 1.0657 - accuracy: 0.7450 - val_loss: 0.9284 - val_accuracy: 0.7703\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.7301 - accuracy: 0.8230 - val_loss: 0.7109 - val_accuracy: 0.8193\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.5465 - accuracy: 0.8650 - val_loss: 0.5874 - val_accuracy: 0.8450\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.4328 - accuracy: 0.8914 - val_loss: 0.5110 - val_accuracy: 0.8600\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.3541 - accuracy: 0.9103 - val_loss: 0.4596 - val_accuracy: 0.8716\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.2967 - accuracy: 0.9250 - val_loss: 0.4260 - val_accuracy: 0.8796\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.2529 - accuracy: 0.9358 - val_loss: 0.4036 - val_accuracy: 0.8858\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.2179 - accuracy: 0.9450 - val_loss: 0.3807 - val_accuracy: 0.8921\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.1898 - accuracy: 0.9530 - val_loss: 0.3670 - val_accuracy: 0.8949\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.1672 - accuracy: 0.9582 - val_loss: 0.3598 - val_accuracy: 0.8964\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.1484 - accuracy: 0.9628 - val_loss: 0.3534 - val_accuracy: 0.8989\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.1329 - accuracy: 0.9660 - val_loss: 0.3468 - val_accuracy: 0.8994\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 0.1188 - accuracy: 0.9692 - val_loss: 0.3472 - val_accuracy: 0.9005\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.1079 - accuracy: 0.9724 - val_loss: 0.3431 - val_accuracy: 0.9015\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.0970 - accuracy: 0.9757 - val_loss: 0.3457 - val_accuracy: 0.9016\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 0.0871 - accuracy: 0.9787 - val_loss: 0.3445 - val_accuracy: 0.9022\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.0800 - accuracy: 0.9802 - val_loss: 0.3458 - val_accuracy: 0.9028\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0717 - accuracy: 0.9828 - val_loss: 0.3553 - val_accuracy: 0.9029\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0664 - accuracy: 0.9842 - val_loss: 0.3568 - val_accuracy: 0.9013\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0604 - accuracy: 0.9859 - val_loss: 0.3567 - val_accuracy: 0.9016\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0550 - accuracy: 0.9875 - val_loss: 0.3568 - val_accuracy: 0.9034\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.0506 - accuracy: 0.9888 - val_loss: 0.3601 - val_accuracy: 0.9027\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.3716 - val_accuracy: 0.9012\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0423 - accuracy: 0.9910 - val_loss: 0.3751 - val_accuracy: 0.9010\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.0389 - accuracy: 0.9918 - val_loss: 0.3773 - val_accuracy: 0.9015\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0360 - accuracy: 0.9924 - val_loss: 0.3820 - val_accuracy: 0.9020\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0327 - accuracy: 0.9934 - val_loss: 0.3890 - val_accuracy: 0.9004\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0301 - accuracy: 0.9941 - val_loss: 0.3944 - val_accuracy: 0.9007\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.3970 - val_accuracy: 0.9002\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.4055 - val_accuracy: 0.8992\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0232 - accuracy: 0.9955 - val_loss: 0.4118 - val_accuracy: 0.8992\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.0212 - accuracy: 0.9963 - val_loss: 0.4139 - val_accuracy: 0.8993\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.0195 - accuracy: 0.9964 - val_loss: 0.4164 - val_accuracy: 0.8996\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 0.4239 - val_accuracy: 0.8993\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 0.4340 - val_accuracy: 0.8982\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.4317 - val_accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.4419 - val_accuracy: 0.8981\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.4394 - val_accuracy: 0.8985\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.4418 - val_accuracy: 0.8989\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.4475 - val_accuracy: 0.8988\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.4568 - val_accuracy: 0.8980\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.4546 - val_accuracy: 0.8979\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.4619 - val_accuracy: 0.8982\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.4677 - val_accuracy: 0.8974\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.4704 - val_accuracy: 0.8974\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.4738 - val_accuracy: 0.8976\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.4828 - val_accuracy: 0.8966\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.4814 - val_accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e55bc2c80>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(x=x_train, y=y_train, batch_size=32, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the predicted labels on a single test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intelogic trace inc. , san antonio , texas , said it bought 2.7 million shares , or about 18 % , of its common stock from an unaffiliated shareholder for $ 3.625 a share , or $ 9.9 million .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP NNP NNP , NNP NNP , NNP , VBD PRP VBD CD CD NNS , CC IN CD NN , IN PRP$ JJ NN IN DT JJ NN IN $ CD DT NN , CC $ CD CD .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['nnp', 'nns', 'nnp', 'nnp', 'nnp', 'nnp', 'vbd', 'prp', 'vbd',\n",
       "        'cd', 'cd', 'nns', 'cc', 'rb', 'cd', 'nn', 'in', 'prp', 'nn',\n",
       "        'nn', 'in', 'dt', 'jj', 'nn', 'in', 'jj', 'dt', 'nn', 'cc', 'cd',\n",
       "        'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd',\n",
       "        'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd']],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without using punctuation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vocabulary_labels[np.argmax(baseline_model(x_test[0:1]), axis=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NNP', 'NNS', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'VBD',\n",
       "        'PRP', 'VBD', 'CD', 'CD', 'NNS', ',', 'CC', 'RB', 'CD', 'NN',\n",
       "        ',', 'IN', 'PRP$', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', '$',\n",
       "        'CD', 'DT', 'NN', ',', 'CC', '$', 'CD', 'CD', '.', '.', '.', '.',\n",
       "        '.', '.', '.', '.', '.', '.', '.']], dtype='<U5')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocabulary_labels[np.argmax(baseline_model(x_test[0:1]), axis=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 23ms/step - loss: 0.9275 - accuracy: 0.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9275322556495667, 0.8213129043579102]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without using puncutation\n",
    "baseline_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4593 - accuracy: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45929422974586487, 0.899909496307373]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d14990a399795653de35f1f5395269163893147857e74010bc072f6042c8e8da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
